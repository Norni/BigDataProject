# configure agent
a1.sources = r1
a1.channels = c1 c2

# configure source
a1.sources.r1.type = TAILDIR
a1.sources.r1.positionFile = /home/nuochengze/datawarehouse_project/data/flume/file_position/taildir_position.json
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /home/nuochengze/datawarehouse_project/data/simulation_data/log_data/applog_data_store/app.+
a1.sources.r1.fileHeader = true

# interceptor
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = com.nuochengze.flume.interceptor.LogETLInterceptor$Builder


a1.sources.r1.selector.type = multiplexing
a1.sources.r1.selector.header = topic
a1.sources.r1.selector.mapping.topic_start = c1
a1.sources.r1.selector.mapping.topic_event = c2

# configure channel
a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c1.kafka.bootstrap.servers = node001:9092,node002:9092:node003:9092
a1.channels.c1.kafka.topic = topic_start
a1.chanenls.c1.parseAsFlumeEvent = false
a1.channels.c1.kafka.consumer.group.id = flume-consumer

a1.channels.c2.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c2.kafka.bootstrap.servers = node001:9092,node002:9092:node003:9092
a1.channels.c2.kafka.topic = topic_event
a1.chanenls.c2.parseAsFlumeEvent = false
a1.channels.c2.kafka.consumer.group.id = flume-consumer

# bind
a1.sources.r1.channels = c1 c2
